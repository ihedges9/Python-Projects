{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ian Hedges and Collin Glover"
      ],
      "metadata": {
        "id": "AwcCbDZXuFlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose this dataset because a process like conrete production has many steps/features that can impact the final performance of the concrete. The dataset is also relevant because it shows how regression and machine learning can be used to predict and improve things we use/interact with on a daily basis, like the concrete we use for bridges, roads, foundations, etc.\n",
        "\n",
        "We felt this dataset was complex due to it having over a thousand instances which provides us with plenty of data. We chose a dataset with this many features so there was no overcomplication of the dataset which can distract from the scope of the project."
      ],
      "metadata": {
        "id": "2QP1FbsbPWAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries and Data"
      ],
      "metadata": {
        "id": "UvRBE-jot4iP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZrRbezdvqv-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "2131c076-7da3-452c-e382-d43a1bb69665"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Concrete_Data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8caa6d0ffa5a>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Loading dataset into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Concrete_Data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Concrete_Data.csv'"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
        "\n",
        "# Loading dataset into a pandas DataFrame\n",
        "data = pd.DataFrame(pd.read_csv(\"/content/Concrete_Data.csv\", sep=','))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "RLtXbmP3uDih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Perform exploratory data analysis (EDA)\n",
        "# Summary statistics\n",
        "print(\"Summary Statistics:\")\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "7BfR12G2w8sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# According to summary on UCI, there are no missing values. This is to verify that is true.\n",
        "data.isna().sum()\n",
        "data.info()"
      ],
      "metadata": {
        "id": "5j-kglSVzyEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.hist(bins=50, figsize=(20, 15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_e6lxauhRNtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.corr()"
      ],
      "metadata": {
        "id": "tzOcBurjO7F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data = data)"
      ],
      "metadata": {
        "id": "vCb3NNqHQtDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(data = data.corr(), annot=True)"
      ],
      "metadata": {
        "id": "d4VJ17LQQ_dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting Data for Model Training"
      ],
      "metadata": {
        "id": "tdwXyB6ruR1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting, independant and dependant variables\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "print(X)\n",
        "print(y)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "a-s7036e0pyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "print(X_test)\n",
        "print(y_test)\n"
      ],
      "metadata": {
        "id": "uyAPlugN0zU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Model"
      ],
      "metadata": {
        "id": "KSFkbihQuXmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "MWlA4Gdh05lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "pred_vs_test = np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)"
      ],
      "metadata": {
        "id": "IkNwH9cx061F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vizualizing the prediction\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')\n",
        "plt.title('Actual vs. Predicted Concrete Strength')\n",
        "plt.xlabel('Actual Strength')\n",
        "plt.ylabel('Predicted Strength')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "szjCt3wI0-Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance Metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print('MSE:', mean_squared_error(y_test, y_pred))\n",
        "from sklearn.metrics import r2_score\n",
        "print( \"R-squared\", r2_score(y_test,y_pred))\n",
        "r2_score(y_test, y_pred)\n",
        "# Adjusted R-squared formula from: https://stackoverflow.com/questions/49381661/how-do-i-calculate-the-adjusted-r-squared-score-using-scikit-learn\n",
        "print('Adjusted R-squared:', 1-(1-r2_score(y_test, y_pred))*((len(X_test)-1)/(len(X_test)-len(X_test[0])-1)))"
      ],
      "metadata": {
        "id": "mYtaEZb41cu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression Model Insights\n",
        "The linear regression model appears to be a well fit model to the data. When looking at the scatterplot, the data has a very obvious positive linear relationship between the actual values and predicted values, but the points don't fit too tightly to the line. While the R-sqaured value is decent at 0.636, it could be better so we will explore using polynomial regression models."
      ],
      "metadata": {
        "id": "5ksoq5VFcp2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial Regression Model"
      ],
      "metadata": {
        "id": "xB6oAcg5ucud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second Degree Polynomial Regression Model"
      ],
      "metadata": {
        "id": "51v_RbLBuskb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming the data\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(2)\n",
        "X_poly = poly.fit_transform(X)"
      ],
      "metadata": {
        "id": "4YJ1kr3l1euD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining new train and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(X_poly, y, test_size = 0.2, random_state = 0)\n",
        "print('X_poly_test values (One \"row\" of values): \\n',X_poly_test[1])\n",
        "print('y_poly_test values: \\n',y_poly_test[1:11])"
      ],
      "metadata": {
        "id": "-TVyapLc1hec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "poly2regressor = LinearRegression()\n",
        "poly2regressor.fit(X_poly_train, y_poly_train)"
      ],
      "metadata": {
        "id": "HUyafcfw1kSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions with the new model\n",
        "y_poly_pred = poly2regressor.predict(X_poly_test)\n",
        "np.set_printoptions(precision=2)\n",
        "poly_pred_vs_test = np.concatenate((y_poly_pred.reshape(len(y_poly_pred),1), y_poly_test.reshape(len(y_poly_test),1)),1)\n",
        "print(poly_pred_vs_test[1:11])"
      ],
      "metadata": {
        "id": "foFnHCbq1mwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the new model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_poly_test, y_poly_pred)\n",
        "plt.plot([min(y_poly_test), max(y_poly_test)], [min(y_poly_test), max(y_poly_test)], '-', color='red')\n",
        "plt.title('Actual vs. Predicted Concrete Strength')\n",
        "plt.xlabel('Actual Strength')\n",
        "plt.ylabel('Predicted Strength')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kFvIy3V51qr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance Metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('MAE:', mean_absolute_error(y_poly_test, y_poly_pred))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print('MSE:', mean_squared_error(y_poly_test, y_poly_pred))\n",
        "from sklearn.metrics import r2_score\n",
        "print( \"R-squared\", r2_score(y_poly_test,y_poly_pred))\n",
        "polyR2 = r2_score(y_poly_test, y_poly_pred)\n",
        "# Adjusted R-squared formula from: https://stackoverflow.com/questions/49381661/how-do-i-calculate-the-adjusted-r-squared-score-using-scikit-learn\n",
        "print('Adjusted R-squared:', 1-(((1-polyR2)*((len(X_poly_test)-1))/(len(X_poly_test)-len(X_test[0])-1))))"
      ],
      "metadata": {
        "id": "Pn8E6JFj1wOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third Degree Polynomial Regression Model"
      ],
      "metadata": {
        "id": "hZ-1u5uEu0yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming the data\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(3)\n",
        "X_poly = poly.fit_transform(X)"
      ],
      "metadata": {
        "id": "zBkKWwTfu5W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining new train and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(X_poly, y, test_size = 0.2, random_state = 0)\n",
        "print(X_poly_test)\n",
        "print(y_poly_test)"
      ],
      "metadata": {
        "id": "IG2AXQoKu-d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "poly3regressor = LinearRegression()\n",
        "poly3regressor.fit(X_poly_train, y_poly_train)"
      ],
      "metadata": {
        "id": "x3kFzUnXvCHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions with the new model\n",
        "y_poly_pred = poly3regressor.predict(X_poly_test)\n",
        "np.set_printoptions(precision=2)\n",
        "poly_pred_vs_test = np.concatenate((y_poly_pred.reshape(len(y_poly_pred),1), y_poly_test.reshape(len(y_poly_test),1)),1)\n",
        "print(poly_pred_vs_test[1:11])"
      ],
      "metadata": {
        "id": "7EuMBnO6vFws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the new model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_poly_test, y_poly_pred)\n",
        "plt.plot([min(y_poly_test), max(y_poly_test)], [min(y_poly_test), max(y_poly_test)], '-', color='red')\n",
        "plt.title('Actual vs. Predicted Concrete Strength')\n",
        "plt.xlabel('Actual Strength')\n",
        "plt.ylabel('Predicted Strength')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "llNlYM7bvLsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance Metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('MAE:', mean_absolute_error(y_poly_test, y_poly_pred))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print('MSE:', mean_squared_error(y_poly_test, y_poly_pred))\n",
        "from sklearn.metrics import r2_score\n",
        "print( \"R-squared\", r2_score(y_poly_test,y_poly_pred))\n",
        "polyR2 = r2_score(y_poly_test, y_poly_pred)\n",
        "# Adjusted R-squared formula from: https://stackoverflow.com/questions/49381661/how-do-i-calculate-the-adjusted-r-squared-score-using-scikit-learn\n",
        "print('Adjusted R-squared:', 1-(((1-polyR2)*((len(X_poly_test)-1))/(len(X_poly_test)-len(X_test[0])-1))))"
      ],
      "metadata": {
        "id": "pHO5RuU2vRIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fourth Degree Polynomial Regression Model"
      ],
      "metadata": {
        "id": "lzpaQNsDa-4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming the data\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(4)\n",
        "X_poly = poly.fit_transform(X)"
      ],
      "metadata": {
        "id": "kgr3LkHWbEE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining new train and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(X_poly, y, test_size = 0.2, random_state = 0)\n",
        "print(X_poly_test)\n",
        "print(y_poly_test)"
      ],
      "metadata": {
        "id": "n2OkrC_JbKuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "poly4regressor = LinearRegression()\n",
        "poly4regressor.fit(X_poly_train, y_poly_train)"
      ],
      "metadata": {
        "id": "JipAQm1zbNqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions with the new model\n",
        "y_poly_pred = poly4regressor.predict(X_poly_test)\n",
        "np.set_printoptions(precision=2)\n",
        "poly_pred_vs_test = np.concatenate((y_poly_pred.reshape(len(y_poly_pred),1), y_poly_test.reshape(len(y_poly_test),1)),1)\n",
        "print(poly_pred_vs_test[1:11])"
      ],
      "metadata": {
        "id": "tcCHFB5rbQw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the new model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_poly_test, y_poly_pred)\n",
        "plt.plot([min(y_poly_test), max(y_poly_test)], [min(y_poly_test), max(y_poly_test)], '-', color='red')\n",
        "plt.title('Actual vs. Predicted Concrete Strength')\n",
        "plt.xlabel('Actual Strength')\n",
        "plt.ylabel('Predicted Strength')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U1W3_NQIbTnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance Metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('MAE:', mean_absolute_error(y_poly_test, y_poly_pred))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print('MSE:', mean_squared_error(y_poly_test, y_poly_pred))\n",
        "from sklearn.metrics import r2_score\n",
        "print( \"R-squared\", r2_score(y_poly_test,y_poly_pred))\n",
        "polyR2 = r2_score(y_poly_test, y_poly_pred)\n",
        "# Adjusted R-squared formula from: https://stackoverflow.com/questions/49381661/how-do-i-calculate-the-adjusted-r-squared-score-using-scikit-learn\n",
        "print('Adjusted R-squared:', 1-(((1-polyR2)*((len(X_poly_test)-1))/(len(X_poly_test)-len(X_test[0])-1))))"
      ],
      "metadata": {
        "id": "laAcoWShbWET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polynomial Regression Model Insight\n",
        "\n",
        "After running three separate polynomial regression models, each having a different degree, we have concluded that the best fit polynomial regression model is the third degree model. The third degree model has the best R-squared score and also has the lowest MSE which means it has the best fit. After running the fourth degree model, we believe the the fourth degree model over fits the data which leads to it not being a good model to select."
      ],
      "metadata": {
        "id": "ICpuebe5bqQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing Columns and Preparing New Model\n",
        "\n"
      ],
      "metadata": {
        "id": "8HgDM9YipP8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting, independant and dependant variables\n",
        "X2 = data[['Age (day)','Water  (component 4)(kg in a m^3 mixture)', 'Coarse Aggregate  (component 6)(kg in a m^3 mixture)', 'Fine Aggregate (component 7)(kg in a m^3 mixture)', 'Cement (component 1)(kg in a m^3 mixture)']].values\n",
        "y = data.iloc[:, -1].values\n",
        "print(X2)\n",
        "print(y)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X2 = scaler.fit_transform(X2)"
      ],
      "metadata": {
        "id": "94sns78unsVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size = 0.2, random_state = 0)\n",
        "print(X_test)\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "SREb5hzXpc3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fvgzC9xSpgBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "pred_vs_test = np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)"
      ],
      "metadata": {
        "id": "AH1uidXdpjip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vizualizing the prediction\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')\n",
        "plt.title('Actual vs. Predicted Concrete Strength')\n",
        "plt.xlabel('Actual Strength')\n",
        "plt.ylabel('Predicted Strength')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2anZSIJ7pm0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance Metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print('MSE:', mean_squared_error(y_test, y_pred))\n",
        "from sklearn.metrics import r2_score\n",
        "print( \"R-squared\", r2_score(y_test,y_pred))\n",
        "r2_score(y_test, y_pred)\n",
        "# Adjusted R-squared formula from: https://stackoverflow.com/questions/49381661/how-do-i-calculate-the-adjusted-r-squared-score-using-scikit-learn\n",
        "print('Adjusted R-squared:', 1-(1-r2_score(y_test, y_pred))*((len(X_test)-1)/(len(X_test)-len(X_test[0])-1)))"
      ],
      "metadata": {
        "id": "Z_0xGCJcpseV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the columns with high amounts of 0's does not help improve the overall performance of the model."
      ],
      "metadata": {
        "id": "flCASdaWq39d"
      }
    }
  ]
}